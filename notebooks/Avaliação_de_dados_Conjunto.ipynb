{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4 --no-cache-dir --force-reinstall\n",
        "import os\n",
        "os.kill(os.getpid(), 9)  # Isso reinicia o kernel do Colab\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2eFJsDHkGDW",
        "outputId": "9295ba2d-9630-458e-9d49-f3a9e0c62f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m148.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "Successfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZUubYC2cnTF"
      },
      "outputs": [],
      "source": [
        "!pip install rdkit-pypi\n",
        "!pip install lazypredict scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oetpbbhf1wlm"
      },
      "source": [
        "# Limpeza de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAyDvSogcv-z",
        "outputId": "8abd0e7f-171a-480c-9be7-aac68d8f9a7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8195, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/Dataset Both.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "def smiles_valido(smiles):\n",
        "    \"\"\"\n",
        "    Verifica se um SMILES √© v√°lido.\n",
        "\n",
        "    Par√¢metros:\n",
        "        smiles (str): String do SMILES.\n",
        "\n",
        "    Retorna:\n",
        "        bool: True se o SMILES √© v√°lido, False caso contr√°rio.\n",
        "    \"\"\"\n",
        "    if not isinstance(smiles, str) or smiles.strip() == \"\":\n",
        "        return False\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        return mol is not None\n",
        "    except:\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "KLjYO4gghIlO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['SMILES_valido'] = df['SMILES'].apply(smiles_valido)\n",
        "df['SMILES_valido'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "I-0wj2iShqJ-",
        "outputId": "66f32dfd-613f-40b0-dc05-fd29798223a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[17:06:34] WARNING: not removing hydrogen atom without neighbors\n",
            "[17:06:34] WARNING: not removing hydrogen atom without neighbors\n",
            "[17:06:35] WARNING: not removing hydrogen atom without neighbors\n",
            "[17:06:35] WARNING: not removing hydrogen atom without neighbors\n",
            "[17:06:35] WARNING: not removing hydrogen atom without neighbors\n",
            "[17:06:35] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SMILES_valido\n",
              "True    8195\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMILES_valido</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>8195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXv5XuzWcPRs",
        "outputId": "ab69730f-b2fb-4055-f8a8-c75487ca1c12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8195, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.drop(columns=['Chemical', 'Identificador', 'SMILES_valido'], inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH48sZ4Yd-NV",
        "outputId": "39078867-d975-479c-9d31-a2181d21a6dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7865, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df.head()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3q4iPnzjyhl4"
      },
      "outputs": [],
      "source": [
        "df['Results'] = df['Results'].str.lower()\n",
        "df['Type'] = df['Type'].str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfopRKVLvXmd",
        "outputId": "09db042f-febc-40c9-c60b-0993ad8ca5ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6717, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uJrD2XTz7ZmQ"
      },
      "outputs": [],
      "source": [
        "# Mapear os valores para 1 (positivos) e 0 (negativos)\n",
        "mapping = {\"positive\": 1, \"negative\": 0, \"ambiguous\": None, \"inconclusive\": None}\n",
        "df[\"Results\"] = df[\"Results\"].map(mapping)\n",
        "\n",
        "# Remover valores nulos\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4jJlpMY8K6e",
        "outputId": "0a08fb5c-3dd4-42b7-adb4-bd538da11cac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6717, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kqEIU8yvwtlX"
      },
      "outputs": [],
      "source": [
        "# --- Passo 1 ---\n",
        "# Para cada SMILES, identificar quais possuem mais de um tipo\n",
        "smiles_mult_type = df.groupby(\"SMILES\")[\"Type\"].nunique()\n",
        "smiles_mult_type = smiles_mult_type[smiles_mult_type > 1].index\n",
        "\n",
        "# Para os SMILES que possuem mais de um 'Type', manter somente as linhas onde 'Type' √© 'in vivo'\n",
        "df_filtrado = df[~(df[\"SMILES\"].isin(smiles_mult_type) & (df[\"Type\"] != \"in vivo\"))]\n",
        "\n",
        "# Remover duplicatas, se existirem\n",
        "df_filtrado = df_filtrado.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arlR23Xby52M",
        "outputId": "082c3724-5fd0-438c-ff0f-ecb9af32e1ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5290, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_filtrado.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EG6BHGqAyiFh"
      },
      "outputs": [],
      "source": [
        "# --- Passo 2 ---\n",
        "# Agora, identificar quais SMILES (no df filtrado) possuem mais de um 'Results'\n",
        "smiles_mult_result = df_filtrado.groupby(\"SMILES\")[\"Results\"].nunique()\n",
        "smiles_mult_result = smiles_mult_result[smiles_mult_result > 1].index\n",
        "\n",
        "# Remover os SMILES que possuem mais de um resultado\n",
        "df_final = df_filtrado[~df_filtrado[\"SMILES\"].isin(smiles_mult_result)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "bd6K9OmcwtU8",
        "outputId": "f8bcb2db-d266-4416-c998-d6bbe7441346"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Results\n",
              "1.0    1987\n",
              "0.0    1899\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Results</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>1899</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df_final['Results'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K7yuWMnh0WP9"
      },
      "outputs": [],
      "source": [
        "df_final = df_final.drop(columns='Type')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAjhoPqaR-0I"
      },
      "source": [
        "# Estrutura de alerta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nf6TfH3TSB7c"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from tqdm import tqdm\n",
        "from rdkit.Chem import Descriptors,AllChem\n",
        "from rdkit import RDLogger\n",
        "import re\n",
        "\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "# Fun√ß√£o auxiliar para neutralizar SMILES com cargas\n",
        "def neutralizar_smiles(smiles):\n",
        "    \"\"\"\n",
        "    Remove cargas formais de √°tomos representados como [Na+], [Fe+3], [Cl-], etc., convertendo para [Na], [Fe], [Cl], etc.\n",
        "    \"\"\"\n",
        "    if pd.isna(smiles):\n",
        "        return \"\"\n",
        "    return re.sub(r'\\[([A-Z][a-z]?)[+-]?[0-9]*\\]', r'[\\1]', smiles)\n",
        "\n",
        "# Fun√ß√£o para calcular descritores moleculares\n",
        "def calcular_descritores(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return {}\n",
        "    return {desc[0]: desc[1](mol) for desc in Descriptors.descList}\n",
        "\n",
        "# Fun√ß√£o principal com controle de neutraliza√ß√£o\n",
        "def verificar_subestruturas_e_descritores(\n",
        "    df, df_estruturas,\n",
        "    smiles_col='SMILES',\n",
        "    estrutura_smiles_col='SMILES',\n",
        "    neutralizar=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Verifica presen√ßa de subestruturas e calcula descritores moleculares.\n",
        "\n",
        "    Par√¢metros:\n",
        "        df: DataFrame com compostos.\n",
        "        df_estruturas: DataFrame com subestruturas.\n",
        "        smiles_col: nome da coluna de SMILES no df.\n",
        "        estrutura_smiles_col: nome da coluna de SMILES no df_estruturas.\n",
        "        neutralizar: se True, remove carga dos SMILES antes da compara√ß√£o.\n",
        "\n",
        "    Retorna:\n",
        "        DataFrame com descritores e colunas de presen√ßa de subestruturas.\n",
        "    \"\"\"\n",
        "\n",
        "    df_estruturas.columns = df_estruturas.columns.str.strip()\n",
        "\n",
        "    # Preparar os SMILES das subestruturas\n",
        "    if neutralizar:\n",
        "        df_estruturas['SMILES_neutro'] = df_estruturas[estrutura_smiles_col].apply(neutralizar_smiles)\n",
        "    else:\n",
        "        df_estruturas['SMILES_neutro'] = df_estruturas[estrutura_smiles_col]\n",
        "\n",
        "    padroes = {\n",
        "        smiles: Chem.MolFromSmiles(smiles)\n",
        "        for smiles in df_estruturas['SMILES_neutro']\n",
        "        if Chem.MolFromSmiles(smiles) is not None\n",
        "    }\n",
        "\n",
        "    subestrutura_resultados = {smiles: [] for smiles in padroes}\n",
        "    descritores_resultados = {desc[0]: [] for desc in Descriptors.descList}\n",
        "\n",
        "    # Iterar sobre os SMILES dos compostos\n",
        "    for smiles in tqdm(df[smiles_col], desc=\"Processando mol√©culas\", unit=\"mol√©cula\"):\n",
        "        smiles_proc = neutralizar_smiles(smiles) if neutralizar else smiles\n",
        "        mol = Chem.MolFromSmiles(smiles_proc)\n",
        "\n",
        "        for sub_smiles, padrao in padroes.items():\n",
        "            subestrutura_resultados[sub_smiles].append(int(mol.HasSubstructMatch(padrao)) if mol else 0)\n",
        "\n",
        "        descritores = calcular_descritores(smiles_proc)\n",
        "        for desc_nome in descritores_resultados:\n",
        "            descritores_resultados[desc_nome].append(descritores.get(desc_nome, None))\n",
        "\n",
        "    df_subs = pd.DataFrame(subestrutura_resultados)\n",
        "    df_descs = pd.DataFrame(descritores_resultados)\n",
        "    df_final = pd.concat([df.reset_index(drop=True), df_descs, df_subs], axis=1)\n",
        "\n",
        "    return df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2nsvHvoR1kal"
      },
      "outputs": [],
      "source": [
        "df_estruturas = pd.read_csv('/content/Estruturas de alerta.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU3UTAPFSqk0",
        "outputId": "57a15bb5-a9d7-463e-ea5c-d5c4e0c3c9f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando mol√©culas: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3886/3886 [00:52<00:00, 73.39mol√©cula/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3886, 362)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "df_processado = verificar_subestruturas_e_descritores(\n",
        "    df=df_final,\n",
        "    df_estruturas=df_estruturas,\n",
        "    smiles_col='SMILES',\n",
        "    estrutura_smiles_col='SMILES'\n",
        ")\n",
        "df_processado.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OudhqyL_vS_i"
      },
      "source": [
        "# Classifica√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GZhVWLDy281o"
      },
      "outputs": [],
      "source": [
        "# Carregar os dados\n",
        "df = df_processado.copy()\n",
        "\n",
        "# Definir as features (X) e o alvo (y)\n",
        "X = df.drop(columns=['SMILES', 'Results'])  # Remove colunas n√£o num√©ricas\n",
        "y = df['Results']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf0PrbRW_g0f"
      },
      "outputs": [],
      "source": [
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Dividir os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar os dados para melhor desempenho dos modelos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Criar e rodar o LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions1 = clf.fit(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbhBwr1yojBt",
        "outputId": "34460612-a88b-4cdc-91dd-d4ff0e7c931e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
            "Model                                                                           \n",
            "ExtraTreesClassifier               0.74               0.74     0.74      0.74   \n",
            "SVC                                0.74               0.74     0.74      0.74   \n",
            "NuSVC                              0.74               0.74     0.74      0.74   \n",
            "LGBMClassifier                     0.73               0.73     0.73      0.73   \n",
            "XGBClassifier                      0.72               0.72     0.72      0.72   \n",
            "LinearDiscriminantAnalysis         0.72               0.72     0.72      0.72   \n",
            "RidgeClassifier                    0.72               0.72     0.72      0.72   \n",
            "RidgeClassifierCV                  0.72               0.72     0.72      0.72   \n",
            "LinearSVC                          0.72               0.72     0.72      0.72   \n",
            "CalibratedClassifierCV             0.72               0.71     0.71      0.71   \n",
            "RandomForestClassifier             0.71               0.71     0.71      0.71   \n",
            "LogisticRegression                 0.71               0.71     0.71      0.71   \n",
            "KNeighborsClassifier               0.71               0.71     0.71      0.71   \n",
            "BaggingClassifier                  0.69               0.69     0.69      0.69   \n",
            "DecisionTreeClassifier             0.67               0.67     0.67      0.67   \n",
            "LabelPropagation                   0.66               0.66     0.66      0.66   \n",
            "LabelSpreading                     0.66               0.66     0.66      0.66   \n",
            "Perceptron                         0.66               0.66     0.66      0.66   \n",
            "SGDClassifier                      0.66               0.66     0.66      0.66   \n",
            "ExtraTreeClassifier                0.65               0.65     0.65      0.65   \n",
            "BernoulliNB                        0.64               0.64     0.64      0.63   \n",
            "AdaBoostClassifier                 0.63               0.63     0.63      0.62   \n",
            "NearestCentroid                    0.61               0.62     0.62      0.61   \n",
            "PassiveAggressiveClassifier        0.59               0.59     0.59      0.58   \n",
            "GaussianNB                         0.58               0.57     0.57      0.51   \n",
            "QuadraticDiscriminantAnalysis      0.57               0.56     0.56      0.50   \n",
            "DummyClassifier                    0.51               0.50     0.50      0.35   \n",
            "\n",
            "                               Time Taken  \n",
            "Model                                      \n",
            "ExtraTreesClassifier                 1.26  \n",
            "SVC                                  2.13  \n",
            "NuSVC                                2.56  \n",
            "LGBMClassifier                       1.72  \n",
            "XGBClassifier                        1.79  \n",
            "LinearDiscriminantAnalysis           0.39  \n",
            "RidgeClassifier                      0.11  \n",
            "RidgeClassifierCV                    0.36  \n",
            "LinearSVC                           31.65  \n",
            "CalibratedClassifierCV              95.38  \n",
            "RandomForestClassifier               1.87  \n",
            "LogisticRegression                   0.60  \n",
            "KNeighborsClassifier                 0.20  \n",
            "BaggingClassifier                    2.82  \n",
            "DecisionTreeClassifier               0.47  \n",
            "LabelPropagation                     0.70  \n",
            "LabelSpreading                       0.99  \n",
            "Perceptron                           0.13  \n",
            "SGDClassifier                        0.28  \n",
            "ExtraTreeClassifier                  0.09  \n",
            "BernoulliNB                          0.11  \n",
            "AdaBoostClassifier                   2.06  \n",
            "NearestCentroid                      0.16  \n",
            "PassiveAggressiveClassifier          0.15  \n",
            "GaussianNB                           0.10  \n",
            "QuadraticDiscriminantAnalysis        0.36  \n",
            "DummyClassifier                      0.08  \n"
          ]
        }
      ],
      "source": [
        "print(models)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.svm import NuSVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "import pandas as pd\n",
        "\n",
        "# Valida√ß√£o cruzada\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# M√©tricas que queremos avaliar\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': 'precision',\n",
        "    'recall': 'recall',\n",
        "    'f1': 'f1',\n",
        "    'roc_auc': 'roc_auc'\n",
        "}\n",
        "\n",
        "# Dicion√°rio com modelos, pipelines e grids\n",
        "modelos = {\n",
        "    \"XGBoost\": {\n",
        "        \"pipeline\": Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"model\", XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
        "        ]),\n",
        "        \"param_grid\": {\n",
        "            \"model__n_estimators\": [50, 100],\n",
        "            \"model__max_depth\": [3, 6],\n",
        "            \"model__learning_rate\": [0.01, 0.1]\n",
        "        }\n",
        "    },\n",
        "    \"RandomForest\": {\n",
        "        \"pipeline\": Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"model\", RandomForestClassifier(random_state=42))\n",
        "        ]),\n",
        "        \"param_grid\": {\n",
        "            \"model__n_estimators\": [50, 100],\n",
        "            \"model__max_depth\": [3, 6]\n",
        "        }\n",
        "    },\n",
        "    \"ExtraTrees\": {\n",
        "        \"pipeline\": Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"model\", ExtraTreesClassifier(random_state=42))\n",
        "        ]),\n",
        "        \"param_grid\": {\n",
        "            \"model__n_estimators\": [50, 100],\n",
        "            \"model__max_depth\": [3, 6]\n",
        "        }\n",
        "    },\n",
        "    \"NuSVC\": {\n",
        "        \"pipeline\": Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"model\", NuSVC(probability=True))\n",
        "        ]),\n",
        "        \"param_grid\": {\n",
        "            \"model__nu\": [0.25, 0.5, 0.75],\n",
        "            \"model__kernel\": ['rbf', 'poly']\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Executar GridSearch para cada modelo e armazenar os resultados\n",
        "resultados_finais = []\n",
        "\n",
        "for nome_modelo, config in modelos.items():\n",
        "    print(f\"\\nüîç Treinando modelo: {nome_modelo}\")\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        estimator=config[\"pipeline\"],\n",
        "        param_grid=config[\"param_grid\"],\n",
        "        scoring=scoring,\n",
        "        refit=\"f1\",\n",
        "        cv=cv,\n",
        "        verbose=1,\n",
        "        n_jobs=-1,\n",
        "        return_train_score=True\n",
        "    )\n",
        "\n",
        "    grid.fit(X, y)\n",
        "\n",
        "    # Resultados em DataFrame\n",
        "    df_resultado = pd.DataFrame(grid.cv_results_)\n",
        "    df_resultado['modelo'] = nome_modelo\n",
        "    resultados_finais.append(df_resultado)\n",
        "\n",
        "    # Mostrar melhores par√¢metros do modelo atual\n",
        "    print(f\"‚úÖ Melhor F1 ({nome_modelo}): {grid.best_score_:.4f}\")\n",
        "    print(f\"Melhores par√¢metros: {grid.best_params_}\")\n",
        "\n",
        "# Juntar todos os resultados\n",
        "df_comparacao = pd.concat(resultados_finais, ignore_index=True)\n",
        "\n",
        "# Filtrar e ordenar os principais resultados por F1\n",
        "colunas_mostrar = ['modelo', 'mean_test_accuracy', 'mean_test_precision',\n",
        "                   'mean_test_recall', 'mean_test_f1', 'mean_test_roc_auc', 'params']\n",
        "\n",
        "df_resultados_finais = df_comparacao[colunas_mostrar].sort_values(\n",
        "    by=\"mean_test_f1\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6nJlX8Fasqg",
        "outputId": "cad76621-c6d4-4b67-d4b1-5d74dcbf96b9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Treinando modelo: XGBoost\n",
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "‚úÖ Melhor F1 (XGBoost): 0.7271\n",
            "Melhores par√¢metros: {'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 100}\n",
            "\n",
            "üîç Treinando modelo: RandomForest\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "‚úÖ Melhor F1 (RandomForest): 0.6984\n",
            "Melhores par√¢metros: {'model__max_depth': 6, 'model__n_estimators': 100}\n",
            "\n",
            "üîç Treinando modelo: ExtraTrees\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "‚úÖ Melhor F1 (ExtraTrees): 0.6484\n",
            "Melhores par√¢metros: {'model__max_depth': 6, 'model__n_estimators': 100}\n",
            "\n",
            "üîç Treinando modelo: NuSVC\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "‚úÖ Melhor F1 (NuSVC): 0.7316\n",
            "Melhores par√¢metros: {'model__kernel': 'rbf', 'model__nu': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Melhor modelo"
      ],
      "metadata": {
        "id": "b5jvHtEFbciT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J0-ZT6u-4PY",
        "outputId": "a3452aa1-f995-4549-d1c0-2c2ee21ace32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Resultados m√©dios na valida√ß√£o cruzada:\n",
            "accuracy  : 0.7316 ¬± 0.0199\n",
            "precision : 0.7349 ¬± 0.0223\n",
            "recall    : 0.7438 ¬± 0.0209\n",
            "f1        : 0.7392 ¬± 0.0188\n",
            "roc_auc   : 0.8027 ¬± 0.0242\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# Pipeline com scaler + modelo\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", ExtraTreesClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Estrat√©gia de valida√ß√£o cruzada\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Avaliar o modelo usando cross_validate com m√∫ltiplas m√©tricas\n",
        "resultados = cross_validate(\n",
        "    pipeline,\n",
        "    X, y,\n",
        "    cv=cv,\n",
        "    scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Mostrar m√©tricas m√©dias\n",
        "print(\"üîç Resultados m√©dios na valida√ß√£o cruzada:\")\n",
        "for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
        "    mean = resultados[f'test_{metric}'].mean()\n",
        "    std = resultados[f'test_{metric}'].std()\n",
        "    print(f\"{metric:<10}: {mean:.4f} ¬± {std:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmQeiA0TXCpT"
      },
      "source": [
        "# Conclus√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3MnKjmxXEP0"
      },
      "source": [
        "Os resultados obtidos por meio da valida√ß√£o cruzada demonstram um desempenho consistente e satisfat√≥rio do modelo avaliado. A acur√°cia m√©dia de 73,16% indica uma boa capacidade global de classifica√ß√£o, enquanto os valores de precis√£o (73,49%) e revoca√ß√£o (74,38%) apontam para um desempenho equilibrado entre a correta identifica√ß√£o das classes positivas e a minimiza√ß√£o de falsos positivos.\n",
        "\n",
        "O F1-score m√©dio de 0,7392 refor√ßa essa harmonia entre precis√£o e revoca√ß√£o, sendo particularmente relevante em contextos onde o balanceamento entre essas m√©tricas √© cr√≠tico. Al√©m disso, o AUC-ROC m√©dio de 0,8027 revela uma adequada capacidade discriminativa do modelo, evidenciando sua efic√°cia na diferencia√ß√£o entre as classes.\n",
        "\n",
        "Os baixos desvios padr√£o observados entre os folds da valida√ß√£o cruzada sugerem estabilidade e robustez no comportamento do modelo, o que √© desej√°vel para aplica√ß√µes em ambientes com variabilidade nos dados. Tais resultados indicam que o modelo est√° bem ajustado ao problema proposto, apresentando potencial para ser utilizado em contextos pr√°ticos ou como base para itera√ß√µes adicionais no pipeline de modelagem."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "1fDFwLNNtSIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results obtained through cross-validation demonstrate a consistent and satisfactory performance of the evaluated model. The mean accuracy of 73.16% indicates good overall classification capability, while the precision (73.49%) and recall (74.38%) values reflect a balanced performance in correctly identifying positive instances and minimizing false positives.\n",
        "\n",
        "The mean F1-score of 0.7392 further supports this balance between precision and recall, which is particularly important in scenarios where both metrics are critical. Additionally, the mean AUC-ROC of 0.8027 highlights the model‚Äôs ability to effectively discriminate between classes.\n",
        "\n",
        "The low standard deviations observed across cross-validation folds suggest that the model exhibits stable and robust behavior, which is desirable for applications involving data variability. These results indicate that the model is well-suited to the problem at hand and may serve as a reliable solution in practical settings or as a foundation for further optimization within the modeling pipeline."
      ],
      "metadata": {
        "id": "aj6w9D9YtX9Y"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}